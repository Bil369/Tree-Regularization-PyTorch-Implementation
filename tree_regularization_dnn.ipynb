{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# hyper-parameters about DNN model\n",
    "input_size = 30\n",
    "hidden_size = 180\n",
    "num_classes = 2\n",
    "# hyper-parameters about optimizer\n",
    "learning_rate = 0.001\n",
    "momentum = 0.9\n",
    "# Hyper-parameters about training control\n",
    "batch_size = 32\n",
    "num_iters = 300\n",
    "iters_retrain = 25\n",
    "num_retrains = num_iters // iters_retrain\n",
    "lambda_punish = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet(nn.Module):\n",
    "    \n",
    "    '''Fully connected neural network with one hidden layer\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size) \n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, num_classes)  \n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SurrogateModel(nn.Module):\n",
    "    \n",
    "    '''Fully connected neural network with one hidden layer\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, input_size):\n",
    "        super(SurrogateModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 7500) \n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(7500, 1)  \n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        out = out.squeeze(-1) # if not squeeze, out has dim (n_samples, 1). After squeeze, out has dim (n_samples) same to the y_true\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_jth_minibatach(j, batch_size, X_train, y_train):\n",
    "    '''返回数据集中的第j个minibatch\n",
    "       \n",
    "       @param j: 第j次iters_retrain\n",
    "       @param batch_size: int\n",
    "       @param X_train: torch.tensor\n",
    "       @param y_train: torch.tensor\n",
    "    '''\n",
    "    num_data = X_train.size(0)\n",
    "    num_minibatches = num_data // batch_size + ((num_data % batch_size) > 0)\n",
    "    j = j % num_minibatches\n",
    "    start = j * batch_size\n",
    "    stop = start + batch_size\n",
    "    return X_train[start:stop], y_train[start:stop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_num_weights(model):\n",
    "    '''返回模型的weights参数个数\n",
    "    '''\n",
    "    num_weights = 0\n",
    "    for key, value in model.state_dict().items():\n",
    "        if key.endswith('weight'):\n",
    "            num_weights += torch.prod(torch.tensor(value.size()))\n",
    "    return num_weights.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_row_weights(model_state_dict):\n",
    "    row_weights = []\n",
    "    for key, value in model_state_dict.items():\n",
    "        if key.endswith('weight'):\n",
    "            row_weights.append(value.view(-1))\n",
    "    return torch.cat(row_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_APL_dataset(saved_model_state_dict, X_train):\n",
    "    tmp_model = NeuralNet(input_size, hidden_size, num_classes)\n",
    "    X_APL_train = torch.zeros(iters_retrain, get_num_weights(tmp_model))\n",
    "    y_APL_train = torch.zeros(iters_retrain)\n",
    "    for i in range(len(saved_model_state_dict)):\n",
    "        tmp_model.load_state_dict(saved_model_state_dict[i])\n",
    "        X_train.to(device)\n",
    "        outputs = tmp_model(X_train)\n",
    "        _, y_pred = torch.max(outputs.data, 1)\n",
    "        tree = DecisionTreeClassifier()\n",
    "        X_train.to(torch.device('cpu'))\n",
    "        y_pred.to(torch.device('cpu'))\n",
    "        tree.fit(X_train.numpy(), y_pred.numpy())\n",
    "        decision_path_matrix = tree.decision_path(X_train.numpy())\n",
    "        apl = decision_path_matrix.sum() / X_train.size(0)\n",
    "        y_APL_train[i] = apl\n",
    "        X_APL_train[i] = get_row_weights(saved_model_state_dict[i])\n",
    "    return X_APL_train, y_APL_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset\n",
    "data = load_breast_cancer()\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.data, data.target, test_size=0.25, random_state=2020)\n",
    "X_train, X_test = torch.tensor(X_train, dtype=torch.float), torch.tensor(X_test, dtype=torch.float)\n",
    "y_train, y_test = torch.tensor(y_train, dtype=torch.long), torch.tensor(y_test, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training DNN model......\n",
      "DNN iters: [10]/[300] loss: 0.58 APL: 0.03\n",
      "DNN iters: [20]/[300] loss: 0.54 APL: 0.03\n",
      "Train surrogate model......\n",
      "Surrogate iters: [10]/[50] loss: 8.41\n",
      "Surrogate iters: [20]/[50] loss: 4.95\n",
      "Surrogate iters: [30]/[50] loss: 3.38\n",
      "Surrogate iters: [40]/[50] loss: 3.44\n",
      "Surrogate iters: [50]/[50] loss: 3.05\n",
      "Training DNN model......\n",
      "DNN iters: [30]/[300] loss: 1.39 APL: 7.22\n",
      "DNN iters: [40]/[300] loss: 1.33 APL: 7.40\n",
      "DNN iters: [50]/[300] loss: 1.29 APL: 7.47\n",
      "Train surrogate model......\n",
      "Surrogate iters: [10]/[50] loss: 3.27\n",
      "Surrogate iters: [20]/[50] loss: 2.90\n",
      "Surrogate iters: [30]/[50] loss: 2.36\n",
      "Surrogate iters: [40]/[50] loss: 1.59\n",
      "Surrogate iters: [50]/[50] loss: 1.63\n",
      "Training DNN model......\n",
      "DNN iters: [60]/[300] loss: 0.73 APL: 1.81\n",
      "DNN iters: [70]/[300] loss: 0.89 APL: 1.81\n",
      "Train surrogate model......\n",
      "Surrogate iters: [10]/[50] loss: 3.81\n",
      "Surrogate iters: [20]/[50] loss: 3.69\n",
      "Surrogate iters: [30]/[50] loss: 3.61\n",
      "Surrogate iters: [40]/[50] loss: 3.59\n",
      "Surrogate iters: [50]/[50] loss: 3.58\n",
      "Training DNN model......\n",
      "DNN iters: [80]/[300] loss: 0.69 APL: 2.94\n",
      "DNN iters: [90]/[300] loss: 0.81 APL: 2.94\n",
      "DNN iters: [100]/[300] loss: 0.97 APL: 2.94\n",
      "Train surrogate model......\n",
      "Surrogate iters: [10]/[50] loss: 0.03\n",
      "Surrogate iters: [20]/[50] loss: 0.05\n",
      "Surrogate iters: [30]/[50] loss: 0.04\n",
      "Surrogate iters: [40]/[50] loss: 0.03\n",
      "Surrogate iters: [50]/[50] loss: 0.02\n",
      "Training DNN model......\n",
      "DNN iters: [110]/[300] loss: 0.76 APL: 0.87\n",
      "DNN iters: [120]/[300] loss: 0.77 APL: 0.87\n",
      "Train surrogate model......\n",
      "Surrogate iters: [10]/[50] loss: 0.01\n",
      "Surrogate iters: [20]/[50] loss: 0.01\n",
      "Surrogate iters: [30]/[50] loss: 0.00\n",
      "Surrogate iters: [40]/[50] loss: 0.00\n",
      "Surrogate iters: [50]/[50] loss: 0.00\n",
      "Training DNN model......\n",
      "DNN iters: [130]/[300] loss: 0.75 APL: 0.97\n",
      "DNN iters: [140]/[300] loss: 0.70 APL: 0.97\n",
      "DNN iters: [150]/[300] loss: 0.77 APL: 0.97\n",
      "Train surrogate model......\n",
      "Surrogate iters: [10]/[50] loss: 0.00\n",
      "Surrogate iters: [20]/[50] loss: 0.00\n",
      "Surrogate iters: [30]/[50] loss: 0.00\n",
      "Surrogate iters: [40]/[50] loss: 0.00\n",
      "Surrogate iters: [50]/[50] loss: 0.00\n",
      "Training DNN model......\n",
      "DNN iters: [160]/[300] loss: 0.76 APL: 0.99\n",
      "DNN iters: [170]/[300] loss: 0.78 APL: 0.99\n",
      "Train surrogate model......\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-50-db449ccbb2eb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[0mtrn_x\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m         \u001b[0mtrn_y\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msurrogate_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrn_x\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     46\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion_surrogate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrn_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m         \u001b[0moptimizer_surrogate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 550\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    551\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-68a180c3704e>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfc2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 550\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    551\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\linear.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 87\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mlinear\u001b[1;34m(input, weight, bias)\u001b[0m\n\u001b[0;32m   1608\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1609\u001b[0m         \u001b[1;31m# fused op is marginally faster\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1610\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1611\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1612\u001b[0m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# train\n",
    "model = NeuralNet(input_size, hidden_size, num_classes)\n",
    "# initialize model weights\n",
    "# for m in model.modules():\n",
    "#    if isinstance(m, (nn.Linear)):\n",
    "#        nn.init.xavier_uniform_(m.weight)\n",
    "model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum)\n",
    "\n",
    "# surrogate model\n",
    "surrogate_model = SurrogateModel(get_num_weights(model))\n",
    "# initialize model weights\n",
    "# for m in surrogate_model.modules():\n",
    "#    if isinstance(m, (nn.Linear)):\n",
    "#        nn.init.xavier_uniform_(m.weight)\n",
    "surrogate_model.to(device)\n",
    "criterion_surrogate = nn.MSELoss()\n",
    "optimizer_surrogate = optim.SGD(surrogate_model.parameters(), lr=learning_rate, momentum=momentum)\n",
    "for i in range(num_retrains):\n",
    "    saved_model_state_dict = [] # save the model state dict in each iters_retrain\n",
    "    # train DNN model\n",
    "    print('Training DNN model......')\n",
    "    for j in range(iters_retrain):\n",
    "        trn_x, trn_y = get_jth_minibatach(j, batch_size, X_train, y_train)\n",
    "        trn_x.to(device)\n",
    "        trn_y.to(device)\n",
    "        output = model(trn_x)\n",
    "        path_length = surrogate_model(get_row_weights(model.state_dict()))\n",
    "        loss = criterion(output, trn_y) + lambda_punish * path_length\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        saved_model_state_dict.append(copy.deepcopy(model.state_dict()))\n",
    "        if (i*iters_retrain + j + 1) % 10 == 0:\n",
    "            print('DNN iters: [{0}]/[{1}] loss: {2:.2f} APL: {3:.2f}'.format((i*iters_retrain + j + 1), num_iters, loss, path_length))\n",
    "    # train Decision Tree to get {weights, APL} dataset\n",
    "    X_APL_train, y_APL_train = get_APL_dataset(saved_model_state_dict, X_train)\n",
    "    print('Train surrogate model......')\n",
    "    # train surrogate model\n",
    "    for j in range(50):\n",
    "        trn_x, trn_y = get_jth_minibatach(j, batch_size, X_APL_train, y_APL_train)\n",
    "        trn_x.to(device)\n",
    "        trn_y.to(device)\n",
    "        output = surrogate_model(trn_x)\n",
    "        loss = criterion_surrogate(output, trn_y)\n",
    "        optimizer_surrogate.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer_surrogate.step()\n",
    "        if (j+1) % 10 == 0:\n",
    "            print('Surrogate iters: [{0}]/[50] loss: {1:.2f}'.format(j+1, loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the Breast Cancer dataset: 57.34265734265734 %\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    X_test.to(device)\n",
    "    y_test.to(device)\n",
    "    outputs = model(X_test)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    total += y_test.size(0)\n",
    "    correct += (predicted == y_test).sum().item()\n",
    "\n",
    "    print('Accuracy of the network on the Breast Cancer dataset: {0} %'.format(100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'dnn_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import numpy as np\n",
    "import pydotplus\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# hyper-parameters about DNN model\n",
    "input_size = 30\n",
    "hidden_size = 20\n",
    "num_classes = 2\n",
    "# hyper-parameters about optimizer\n",
    "learning_rate = 0.01\n",
    "momentum = 0.9\n",
    "# Hyper-parameters about training control\n",
    "batch_size = 32\n",
    "num_iters = 300\n",
    "iters_retrain = 20\n",
    "num_retrains = num_iters // iters_retrain\n",
    "lambda_punish = 100 # regularization strength about DNN\n",
    "epsilon_punish = 0.01 # regularization strength about surrogate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet(nn.Module):\n",
    "    \n",
    "    '''Fully connected neural network with one hidden layer\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size) \n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, num_classes)  \n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SurrogateModel(nn.Module):\n",
    "    \n",
    "    '''Fully connected neural network with one hidden layer\n",
    "       Split the fc1 into two parts \n",
    "       because only in this way can have compute graph with DNN model weights\n",
    "       so that can backpropagation to update DNN model weights and this is tree regularization\n",
    "       (maybe have other ways to do this faster. Currently this is not very elegant.)\n",
    "    '''\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(SurrogateModel, self).__init__()\n",
    "        self.fc1_1 = nn.Linear(600, 20)\n",
    "        self.fc1_2 = nn.Linear(40, 20)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(20, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x is the model.state_dict().items()[training] or model.named_parameters()[calculate APL]\n",
    "        for key, value in x:\n",
    "            if key == 'fc1.weight':\n",
    "                out1 = self.fc1_1(value.view(-1))\n",
    "            elif key == 'fc2.weight':\n",
    "                out2 = self.fc1_2(value.view(-1))\n",
    "        out = out1 + out2\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_jth_minibatach(j, batch_size, X_train, y_train):\n",
    "    '''返回数据集中的第j个minibatch\n",
    "       \n",
    "       @param j: 第j次iters_retrain\n",
    "       @param batch_size: int\n",
    "       @param X_train: torch.tensor\n",
    "       @param y_train: torch.tensor\n",
    "    '''\n",
    "    num_data = y_train.size(0)\n",
    "    num_minibatches = num_data // batch_size + ((num_data % batch_size) > 0)\n",
    "    j = j % num_minibatches\n",
    "    start = j * batch_size\n",
    "    stop = start + batch_size\n",
    "    return X_train[start:stop], y_train[start:stop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_num_weights(model):\n",
    "    '''打印模型的各层weight参数个数\n",
    "    '''\n",
    "    for key, value in model.state_dict().items():\n",
    "        if key.endswith('weight'):\n",
    "            print(torch.prod(torch.tensor(value.size())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_y_APL_train(saved_model_state_dict, X_train):\n",
    "    tmp_model = NeuralNet(input_size, hidden_size, num_classes)\n",
    "    tmp_model.to(device)\n",
    "    y_APL_train = torch.zeros(len(saved_model_state_dict))\n",
    "    for i in range(len(saved_model_state_dict)):\n",
    "        tmp_model.load_state_dict(saved_model_state_dict[i])\n",
    "        X_train = X_train.to(device)\n",
    "        outputs = tmp_model(X_train)\n",
    "        _, y_pred = torch.max(outputs.data, 1)\n",
    "        tree = DecisionTreeClassifier(min_samples_leaf=25)\n",
    "        X_train = X_train.to(torch.device('cpu'))\n",
    "        y_pred = y_pred.to(torch.device('cpu'))\n",
    "        tree.fit(X_train.numpy(), y_pred.numpy())\n",
    "        decision_path_matrix = tree.decision_path(X_train.numpy())\n",
    "        apl = decision_path_matrix.sum() / X_train.size(0)\n",
    "        y_APL_train[i] = apl\n",
    "    return y_APL_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset\n",
    "data = load_breast_cancer()\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.data, data.target, test_size=0.25, random_state=2020)\n",
    "X_train, X_test = torch.tensor(X_train, dtype=torch.float), torch.tensor(X_test, dtype=torch.float)\n",
    "y_train, y_test = torch.tensor(y_train, dtype=torch.long), torch.tensor(y_test, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training DNN model......\n",
      "DNN iters: [10]/[300] loss: 1.67\n",
      "DNN iters: [20]/[300] loss: 0.32\n",
      "Accuracy of the network on the Breast Cancer dataset: 74.83 %\n",
      "AUC of the network on the Breast Cancer dataset: 0.89\n",
      "Training DNN model......\n",
      "DNN iters: [30]/[300] loss: 0.17\n",
      "DNN iters: [40]/[300] loss: 0.30\n",
      "Training DNN model......\n",
      "DNN iters: [50]/[300] loss: 0.11\n",
      "DNN iters: [60]/[300] loss: 0.29\n",
      "Training DNN model......\n",
      "DNN iters: [70]/[300] loss: 0.09\n",
      "DNN iters: [80]/[300] loss: 0.25\n",
      "Accuracy of the network on the Breast Cancer dataset: 88.11 %\n",
      "AUC of the network on the Breast Cancer dataset: 0.97\n",
      "Training DNN model......\n",
      "DNN iters: [90]/[300] loss: 0.08\n",
      "DNN iters: [100]/[300] loss: 0.23\n",
      "Training DNN model......\n",
      "DNN iters: [110]/[300] loss: 0.09\n",
      "DNN iters: [120]/[300] loss: 0.22\n",
      "Training DNN model......\n",
      "DNN iters: [130]/[300] loss: 0.13\n",
      "DNN iters: [140]/[300] loss: 0.24\n",
      "Accuracy of the network on the Breast Cancer dataset: 90.21 %\n",
      "AUC of the network on the Breast Cancer dataset: 0.98\n",
      "Training DNN model......\n",
      "DNN iters: [150]/[300] loss: 0.16\n",
      "DNN iters: [160]/[300] loss: 0.23\n",
      "Training DNN model......\n",
      "DNN iters: [170]/[300] loss: 0.15\n",
      "DNN iters: [180]/[300] loss: 0.22\n",
      "Training DNN model......\n",
      "DNN iters: [190]/[300] loss: 0.17\n",
      "DNN iters: [200]/[300] loss: 0.22\n",
      "Accuracy of the network on the Breast Cancer dataset: 91.61 %\n",
      "AUC of the network on the Breast Cancer dataset: 0.98\n",
      "Training DNN model......\n",
      "DNN iters: [210]/[300] loss: 0.18\n",
      "DNN iters: [220]/[300] loss: 0.21\n",
      "Training DNN model......\n",
      "DNN iters: [230]/[300] loss: 0.19\n",
      "DNN iters: [240]/[300] loss: 0.20\n",
      "Training DNN model......\n",
      "DNN iters: [250]/[300] loss: 0.22\n",
      "DNN iters: [260]/[300] loss: 0.19\n",
      "Accuracy of the network on the Breast Cancer dataset: 91.61 %\n",
      "AUC of the network on the Breast Cancer dataset: 0.98\n",
      "Training DNN model......\n",
      "DNN iters: [270]/[300] loss: 0.24\n",
      "DNN iters: [280]/[300] loss: 0.18\n",
      "Training DNN model......\n",
      "DNN iters: [290]/[300] loss: 0.24\n",
      "DNN iters: [300]/[300] loss: 0.18\n"
     ]
    }
   ],
   "source": [
    "# train DNN without tree regularization\n",
    "model = NeuralNet(input_size, hidden_size, num_classes)\n",
    "model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for i in range(num_retrains):\n",
    "    # train DNN model\n",
    "    print('Training DNN model......')\n",
    "    for j in range(iters_retrain):\n",
    "        trn_x, trn_y = get_jth_minibatach(j, batch_size, X_train, y_train)\n",
    "        trn_x = trn_x.to(device)\n",
    "        trn_y = trn_y.to(device)\n",
    "        output = model(trn_x)\n",
    "        loss = criterion(output, trn_y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if (i*iters_retrain + j + 1) % 10 == 0:\n",
    "            print('DNN iters: [{0}]/[{1}] loss: {2:.2f}'.format((i*iters_retrain + j + 1), num_iters, loss.item()))\n",
    "    if i % 3 == 0:\n",
    "        with torch.no_grad():\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            X_test = X_test.to(device)\n",
    "            y_test = y_test.to(device)\n",
    "            outputs = model(X_test)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += y_test.size(0)\n",
    "            correct += (predicted == y_test).sum().item()\n",
    "            y_score = F.softmax(outputs, dim=1)\n",
    "            y_score = y_score[:, 1]\n",
    "\n",
    "            print('Accuracy of the network on the Breast Cancer dataset: {0:.2f} %'.format(100 * correct / total))\n",
    "            print('AUC of the network on the Breast Cancer dataset: {0:.2f}'.format(roc_auc_score(y_test.cpu().numpy(), y_score.cpu().numpy())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training DNN model......\n",
      "DNN iters: [10]/[300] loss: 0.71 Estimated APL: 0.18\n",
      "DNN iters: [20]/[300] loss: 0.54 Estimated APL: 0.18\n",
      "Get {weights, APL} dataset......\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[426]\n",
      "[0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[426]\n",
      "[0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[426]\n",
      "[0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[426]\n",
      "[0]\n",
      "[17 10  2  5  5 15 11 15 15  5 18 15  5 16  5 15  5 18 14 15  5 15 17 15\n",
      " 15  4 18 17  4  4 15  5  5 16 15 16  2 17 14  5 11 15 11  5 14  5 15 18\n",
      " 17 15  5  5  5 18  5  5 10  4 18 15 15 17 17 18 15  5  5 15  5  4 15  5\n",
      " 18  4 14  2 11  5 15 17 18  5  5 15  2 10 15  2 15  2  2 18  5  5  5  5\n",
      " 11 15 15 14 17 16  5  2 18  2  5  5 18 18 17 16  5 15  5 15 18  5 14 17\n",
      "  5  5 15  2  5 15  5 16 18  5 15 18 11  2 15 15 11 18  5  5 17  5  4  5\n",
      " 11 10 17 15 15 10  2  5 18 15 17  5 11  5 14 10 16 15 16 15 15 16 11 18\n",
      "  2  4 15 18 15 10 18 10 14 11  5 14 15 10 18  4  5 17  5 15  5  4 15  2\n",
      " 14  4 11  5  5 18 10 10 15 15 17 14  5 14 10 14 18 15  5 15 11 18  5  2\n",
      " 18  4  5  2  2 15 10 15  5 14 18 16 15 18 15 15 15  2  5 10 16 15 14 11\n",
      " 18 10  5 14  5  5 10 15 14 18 15 17  4 11  5 14  5  2 15 17 15 10  5  5\n",
      "  5  5  2 15  2 18 14 16 15 11  4 15  4  2 18  2 15 15 16 15 18 16  4 15\n",
      "  5 10  5 15 14 18  5  4 16  5 15  5  4 10  4 16 17 10 17 18 15 11 17 15\n",
      "  4 14 16  5 18  5 15 15  5  5  5 18 15  5  5 11 17 14 16  5 15 16  2 18\n",
      "  2 18  5 11  4  5  5 15 10 15 16 15 18 17 15  5 10  5 14 14 15 15 15  5\n",
      "  5 11 15 16 15 15 14  4  5 10 11 15 11  5  5  4 10 18  4 11  5  5  2 16\n",
      "  2 10  5 15 16  5  5  5 11 10 18 10  5 18 17 18 16 10 15  2 15 17 15 11\n",
      " 15  2 11  5 11  5 15 16 10 10  4  2  5 17 15 15 18 18]\n",
      "[  0   0  30   0  25 100   0   0   0   0  30  27   0   0  25  92  25  26\n",
      "  46]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18]\n",
      "[2 2 1 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 1 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 1 2 1 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2\n",
      " 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2\n",
      " 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 1 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "[  0  25 401]\n",
      "[0 1 2]\n",
      "[2 2 1 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 1 2 2 2 2 2 1 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 1 2 1 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2\n",
      " 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 1 2 2 2 1 2 2 2 2 2 2\n",
      " 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 1 2 2 2 2 2 2 2 2 1 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "[  0  25 401]\n",
      "[0 1 2]\n",
      "[4 4 1 4 3 4 4 4 4 4 4 4 1 4 3 4 4 4 4 4 1 4 4 4 4 4 4 4 4 3 4 3 4 4 4 4 4\n",
      " 4 4 4 4 4 4 4 4 4 4 4 4 4 3 3 4 4 4 1 4 4 4 4 4 4 4 4 4 4 3 4 1 4 4 4 4 4\n",
      " 4 1 4 4 4 4 4 1 3 4 4 4 4 1 4 4 3 4 4 1 4 4 4 4 4 4 4 4 1 4 4 4 4 3 4 4 4\n",
      " 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 3 4 4 4 4 1 4 4 4 4 1 4 4 4 4\n",
      " 4 4 4 4 4 4 4 4 4 3 4 4 4 4 4 4 4 4 4 4 4 3 4 4 4 4 4 4 4 4 4 4 4 4 4 1 4\n",
      " 4 4 4 4 4 4 4 4 4 4 3 1 4 4 4 4 4 4 4 3 4 4 4 4 4 4 4 4 4 3 1 4 4 1 4 1 4\n",
      " 4 4 4 4 4 4 4 4 4 4 4 4 1 4 4 4 4 4 4 4 1 4 3 4 4 4 4 4 4 4 4 4 4 4 1 3 4\n",
      " 4 4 4 3 3 4 3 3 4 1 4 4 4 4 4 3 4 4 4 4 4 4 4 4 4 4 4 3 4 1 4 4 4 4 4 1 4\n",
      " 4 4 4 3 4 4 3 4 4 4 4 4 4 4 4 4 4 4 4 3 4 1 4 4 3 3 3 4 4 4 1 4 4 4 4 3 4\n",
      " 4 1 4 4 4 4 4 4 3 4 4 4 4 4 4 4 4 4 4 4 3 4 4 4 4 4 1 3 4 4 4 4 4 4 4 4 4\n",
      " 4 4 4 1 4 3 4 4 4 4 4 3 1 4 1 4 4 4 4 3 4 4 4 4 4 4 3 4 4 4 4 4 4 4 4 4 4\n",
      " 4 4 1 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4]\n",
      "[  0  31   0  38 357]\n",
      "[0 1 2 3 4]\n",
      "[2 2 2 2 2 2 2 3 2 2 2 2 2 7 2 2 2 8 2 7 2 6 8 7 3 2 2 8 2 2 2 2 2 6 8 6 2\n",
      " 2 6 2 2 2 2 2 3 2 2 3 6 3 2 2 2 2 2 2 2 2 3 2 2 2 3 2 7 2 2 6 2 2 7 2 2 2\n",
      " 2 2 2 2 6 2 3 2 2 3 2 2 7 2 3 2 2 2 2 2 2 2 2 7 7 2 2 7 2 2 2 2 2 2 2 2 2\n",
      " 8 2 8 2 2 2 2 6 2 2 2 7 2 2 2 2 8 2 2 6 2 2 2 2 2 2 8 2 2 2 2 2 2 2 2 8 6\n",
      " 2 2 2 2 3 2 8 2 2 2 2 2 6 3 6 2 2 7 2 2 2 2 2 3 8 2 3 2 6 2 2 3 6 2 2 2 2\n",
      " 2 2 2 2 2 2 2 3 2 2 2 2 3 2 2 7 6 2 3 2 2 2 2 8 2 2 2 2 2 2 2 3 2 2 2 2 2\n",
      " 2 8 2 3 2 2 7 8 6 3 2 2 2 2 6 3 2 2 2 2 2 2 2 2 2 3 6 8 3 7 2 2 2 2 2 2 2\n",
      " 2 3 2 2 2 2 2 2 2 2 2 2 7 2 2 2 3 2 2 2 2 2 3 3 3 3 6 2 2 2 2 2 2 3 3 2 2\n",
      " 7 2 2 2 2 2 2 7 6 2 7 8 2 2 6 7 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 8 2 2\n",
      " 8 2 2 2 3 2 2 2 2 2 2 2 8 8 7 8 3 3 2 2 2 2 6 7 2 3 2 2 2 7 8 6 2 2 2 2 2\n",
      " 2 6 2 2 2 2 2 2 2 2 2 2 2 3 2 2 2 7 3 2 2 2 2 2 2 2 2 8 2 8 6 2 2 2 3 2 2\n",
      " 2 7 2 2 2 2 2 2 7 2 2 2 2 2 2 3 3 8 3]\n",
      "[  0   0 309  42   0   0  25  25  25]\n",
      "[0 1 2 3 4 5 6 7 8]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[426]\n",
      "[0]\n",
      "[3 3 3 3 3 3 3 6 3 3 3 3 3 8 3 3 3 8 3 7 3 7 8 8 3 3 3 6 3 3 3 3 3 7 7 6 2\n",
      " 3 6 3 3 2 3 3 8 3 3 3 6 2 3 3 3 3 3 3 3 3 3 3 3 3 3 2 7 3 3 6 3 3 6 3 3 3\n",
      " 3 3 3 3 7 3 3 3 3 3 3 3 6 2 2 3 3 3 3 3 3 3 3 6 6 3 3 7 3 3 3 3 3 3 3 3 3\n",
      " 8 3 7 3 3 3 3 6 3 3 3 8 2 3 3 3 8 3 3 6 3 2 2 3 3 3 8 3 3 3 3 3 3 3 3 7 6\n",
      " 3 3 3 3 8 3 8 3 3 3 3 3 7 3 7 3 3 8 3 3 3 3 3 3 8 3 3 3 6 3 3 3 8 3 3 3 3\n",
      " 3 3 3 3 3 3 3 6 3 3 3 3 3 3 2 7 7 3 2 3 2 3 3 8 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 6 3 6 3 3 6 8 7 3 3 3 3 3 7 3 3 3 3 3 3 3 2 3 3 2 6 8 3 7 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3 3 3 2 3 3 3 2 8 3 3 3 3 3 2 3 2 3 3 8 6 3 7 3 3 3 2 3 3 3 3 3 3\n",
      " 8 3 3 3 3 3 3 8 6 3 6 8 3 3 6 6 3 3 3 3 3 3 3 2 3 3 3 3 3 3 3 3 3 3 8 3 3\n",
      " 8 3 3 3 3 3 3 3 3 3 3 3 7 8 7 8 3 3 3 3 3 2 7 6 2 3 3 3 3 6 7 7 3 3 3 3 3\n",
      " 3 6 3 3 3 3 3 3 3 3 3 3 3 6 3 3 3 6 7 3 3 3 3 3 3 2 3 6 3 8 6 3 2 3 2 3 3\n",
      " 3 7 3 3 3 3 3 3 8 3 3 3 3 3 3 3 3 7 3]\n",
      "[  0   0  25 317   0   0  31  25  28]\n",
      "[0 1 2 3 4 5 6 7 8]\n",
      "[ 9  6  4  4  4 12  9 12 11  4  9 11  4 12  4 12  3 12 11 12  4 12 12 12\n",
      " 12  6  9 12  4  4 12  4  4 12 12 12  6  7 12  3 11 12  7  4 12  3 12 12\n",
      " 12 12  4  4  4 11  4  4  9  4 12 12 11 11 12  9 12  4  4 12  4  4 12  4\n",
      " 11  4 12  3  7  4 12  9 12  3  4 12  6  9 12  3 12  4  3 12  4  4  6  4\n",
      "  7 12 12  9 12 12  4  6 11  4  7  4  6 12  7 12  3 12  7 12 11  7 12  9\n",
      "  7  4 12  3  4 12  4 12 12  4 12 12  9  3  9 12  7 12  4  3  7  7  3  4\n",
      "  9  9 12 12 12  7  6  4 12  9 12  4  9  4 11  6 12 12 12  9 11 12 11 12\n",
      "  3  4 12 12 12  9 12  9 12 11  4 12 12  6 11  4  4  9  4 11  4  4  9  4\n",
      " 12  7  9  4  4 12  9  9 12 12 11 12  4 12  6 12 12 12  4 12 11 11  4  4\n",
      " 12  7  4  6  4 11 11 12  4 12 11  9 12 12 12 12 12  6  4  6 12 12 12  7\n",
      "  9  6  4 11  3  3  9 12 12 12 12 12  4  9  7  9  3  4 12 12 12  6  4  4\n",
      "  4  4  3 12  4 12  9 12 12  9  4 12  4  3 12  3 12 12 12 12 12 12  4  9\n",
      "  4  6  7 12 12 12  4  3 12  3 12  4  4  6  4 12 12 11 12 12 12  7 12 12\n",
      "  7 12 12  4 12  4 11  9  4  4  4 11  9  4  4  7 11 11 12  4 12 12  3 11\n",
      "  6 12  3  7  4  4  4  9  6 12 12 12 12 12 12  4  6  4 12 12 12  9 12  4\n",
      "  4 11 12 12 12 11 12  4  7  9  7 12  9  4  7  4  6  9  7  7  7  4  4 12\n",
      "  3  9  7 12 12  4  4  4  7  6 11  9  4 12 12 12 12  9 11  3 12 11 12  9\n",
      " 12  4  7  4  9  4 12 12  6  6  4  4  4  9 12 12 12 12]\n",
      "[  0   0   0  25 106   0  25  31   0  45   0  34 160]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12]\n",
      "[8 5 3 2 3 7 7 7 7 3 5 7 3 7 2 7 2 7 7 7 3 7 8 7 7 5 7 8 3 3 7 3 3 7 7 7 5\n",
      " 7 7 2 7 7 5 3 8 2 7 7 7 7 2 3 3 7 2 3 7 3 7 7 7 7 7 7 7 2 3 7 3 3 7 2 7 3\n",
      " 7 2 7 5 7 8 7 2 3 7 2 7 7 2 7 3 2 7 3 3 5 3 7 7 7 7 8 7 3 2 7 5 5 3 7 7 5\n",
      " 7 5 7 7 7 7 5 7 8 5 5 8 2 5 7 3 7 7 3 7 8 7 2 7 7 7 7 3 2 5 5 2 3 7 5 7 7\n",
      " 7 5 5 5 7 7 8 3 7 3 7 5 7 7 7 7 7 7 7 7 2 3 8 7 8 7 8 5 7 7 3 7 7 5 7 3 3\n",
      " 8 3 7 2 2 7 2 7 5 7 3 2 7 7 7 7 7 8 7 3 7 5 7 7 7 3 7 7 7 2 3 7 5 3 5 3 7\n",
      " 7 7 3 7 7 8 7 7 7 7 7 5 3 5 7 7 7 5 7 5 3 7 2 2 7 7 7 7 7 7 3 7 5 7 2 2 7\n",
      " 7 7 7 2 3 5 3 2 7 3 7 7 7 7 7 3 7 3 2 7 2 7 7 7 7 7 7 3 7 3 5 3 7 7 7 3 5\n",
      " 7 2 7 3 3 7 3 7 8 7 8 7 7 7 8 7 7 7 7 2 7 2 7 7 3 3 3 7 7 2 3 5 7 7 7 3 8\n",
      " 7 2 7 5 7 5 5 3 3 3 7 7 7 7 7 7 8 7 3 3 3 7 7 7 7 7 3 3 7 7 8 7 7 7 2 7 7\n",
      " 5 7 7 3 2 3 7 7 5 3 7 3 3 7 2 7 3 7 7 3 3 3 5 5 7 7 3 8 7 7 7 7 7 2 7 7 7\n",
      " 7 7 2 8 3 7 5 7 7 5 7 2 3 5 8 7 7 7 7]\n",
      "[  0   0  44  83   0  47   0 227  25]\n",
      "[0 1 2 3 4 5 6 7 8]\n",
      "[2 2 2 2 2 5 2 7 3 2 2 3 2 7 2 5 2 7 5 7 2 7 8 7 7 2 2 8 2 2 5 2 2 7 7 7 2\n",
      " 2 7 2 3 5 2 2 7 2 7 7 8 5 2 2 2 5 2 2 2 2 7 7 3 8 8 2 7 2 2 7 2 2 7 2 8 2\n",
      " 3 2 2 2 7 2 7 2 2 7 2 2 7 2 7 2 2 8 2 2 2 2 2 7 7 3 8 7 2 2 5 2 2 2 5 7 2\n",
      " 7 2 7 2 5 5 2 7 2 2 2 7 2 2 5 2 7 3 2 7 8 2 2 3 7 2 7 2 2 2 2 2 2 2 2 8 7\n",
      " 5 2 2 2 7 3 8 2 2 2 3 2 7 7 7 2 3 7 3 5 2 2 3 7 7 2 8 2 7 5 2 7 7 2 7 2 2\n",
      " 2 2 2 2 2 3 2 7 2 2 2 2 7 2 2 7 7 5 7 2 7 2 5 7 7 2 5 7 2 2 2 7 2 2 2 2 5\n",
      " 7 7 2 7 5 3 7 8 7 7 7 2 2 2 7 7 5 2 3 2 2 5 2 2 2 7 7 7 7 8 2 2 2 3 2 2 5\n",
      " 3 8 2 2 2 2 2 2 7 2 7 3 7 5 2 2 7 2 2 7 2 5 7 7 7 7 7 2 3 2 2 2 5 7 7 2 2\n",
      " 7 2 7 2 2 2 2 7 8 2 8 7 5 2 8 7 2 7 7 2 7 2 5 3 2 2 2 7 3 2 2 2 8 5 7 2 5\n",
      " 7 2 7 2 8 2 2 2 2 2 2 2 7 7 7 7 8 7 2 2 2 7 7 7 3 7 2 2 2 7 7 7 5 7 2 2 2\n",
      " 2 7 2 2 2 2 2 2 2 2 2 2 2 7 2 2 2 7 8 2 2 2 2 2 8 2 2 7 8 8 7 3 5 2 7 5 7\n",
      " 2 7 2 2 2 2 2 5 7 2 2 2 2 2 3 7 7 7 7]\n",
      "[  0   0 221  25   0  34   0 121  25]\n",
      "[0 1 2 3 4 5 6 7 8]\n",
      "[2 2 2 2 2 2 2 5 2 2 2 2 2 6 2 2 2 5 2 6 2 6 6 5 2 2 3 6 2 2 2 2 2 6 6 6 2\n",
      " 2 6 2 2 2 2 2 2 2 2 5 6 2 2 2 2 3 2 3 2 2 5 2 2 2 2 2 6 2 2 6 2 2 6 2 2 2\n",
      " 2 2 2 2 5 2 3 2 2 5 2 2 6 2 2 2 2 3 2 2 2 2 2 6 6 2 2 6 2 2 3 2 2 2 3 3 2\n",
      " 6 2 6 2 2 2 2 6 2 2 3 5 2 2 2 2 6 2 2 6 2 2 2 2 3 2 6 2 2 2 2 2 2 2 2 6 6\n",
      " 2 2 2 2 6 2 6 2 2 2 2 2 6 3 6 2 2 6 2 2 2 2 2 5 6 2 3 2 6 2 2 2 5 2 2 2 2\n",
      " 2 2 2 3 2 2 2 5 2 2 2 2 5 2 2 6 6 2 2 2 2 2 2 6 2 2 2 2 2 2 2 3 2 2 2 2 2\n",
      " 2 6 2 5 3 2 5 6 6 3 2 2 2 2 6 2 2 2 3 2 2 2 2 2 2 2 5 6 5 6 2 2 2 2 2 2 2\n",
      " 2 5 2 2 2 2 2 2 2 2 3 2 6 2 2 2 2 2 2 3 2 2 3 6 5 6 6 2 2 2 2 2 2 2 2 2 2\n",
      " 5 2 2 2 2 2 2 6 6 2 6 5 2 2 6 6 2 2 2 2 3 2 2 2 2 2 2 3 2 2 2 2 2 2 6 2 2\n",
      " 6 2 2 2 3 2 2 2 2 2 2 2 6 6 6 6 2 3 2 2 2 2 5 6 2 2 2 2 2 6 6 6 2 2 2 2 2\n",
      " 2 6 2 2 2 2 2 2 2 2 2 2 2 6 2 2 2 5 6 2 2 2 2 2 3 2 2 6 2 6 6 2 2 2 2 2 2\n",
      " 2 5 2 2 2 2 2 2 5 2 2 2 2 2 2 2 2 6 5]\n",
      "[  0   0 309  25   0  25  67]\n",
      "[0 1 2 3 4 5 6]\n",
      "[2 2 2 2 2 2 2 3 2 2 2 2 2 5 2 2 2 3 2 5 2 5 6 3 2 2 2 6 2 2 2 2 2 6 5 6 2\n",
      " 2 6 2 2 2 2 2 2 2 2 3 5 2 2 2 2 2 2 2 2 2 3 2 2 2 2 2 5 2 2 6 2 2 5 2 2 2\n",
      " 2 2 2 2 3 2 2 2 2 3 2 2 5 2 2 2 2 2 2 2 2 2 2 5 6 2 2 6 2 2 2 2 2 2 2 2 2\n",
      " 6 2 5 2 2 2 2 5 2 2 2 3 2 2 2 2 5 2 2 5 2 2 2 2 2 2 5 2 2 2 2 2 2 2 2 6 5\n",
      " 2 2 2 2 5 2 5 2 2 2 2 2 5 2 6 2 2 5 2 2 2 2 2 3 6 2 2 2 5 2 2 2 3 2 2 2 2\n",
      " 2 2 2 2 2 2 2 3 2 2 2 2 3 2 2 6 6 2 2 2 2 2 2 5 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 5 2 3 2 2 5 6 5 2 2 2 2 2 5 2 2 2 2 2 2 2 2 2 2 2 3 5 3 6 2 2 2 2 2 2 2\n",
      " 2 3 2 2 2 2 2 2 2 2 2 2 5 2 2 2 2 2 2 2 2 2 2 6 3 5 6 2 2 2 2 2 2 2 3 2 2\n",
      " 3 2 2 2 2 2 2 6 5 2 6 3 2 2 5 5 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 5 2 2\n",
      " 6 2 2 2 2 2 2 2 2 2 2 2 5 5 5 6 2 2 2 2 2 2 3 5 2 2 2 2 2 5 6 5 2 2 2 2 2\n",
      " 2 5 2 2 2 2 2 2 2 2 2 2 2 5 2 2 2 3 3 2 2 2 2 2 2 2 2 5 2 6 5 2 2 2 2 2 2\n",
      " 2 3 2 2 2 2 2 2 3 2 2 2 2 2 2 2 2 5 6]\n",
      "[  0   0 333  25   0  43  25]\n",
      "[0 1 2 3 4 5 6]\n",
      "[2 2 2 2 2 2 2 5 2 2 2 2 2 6 2 2 2 5 2 6 2 6 6 5 5 2 2 6 2 2 2 2 2 6 6 6 2\n",
      " 2 6 2 2 2 2 2 3 2 2 5 6 2 2 2 2 2 2 2 2 2 5 2 2 3 5 2 6 2 2 6 2 2 6 2 2 2\n",
      " 2 2 2 2 5 2 3 2 2 5 2 2 6 2 3 2 2 2 2 2 2 2 2 6 6 2 5 6 2 2 2 2 2 2 2 3 2\n",
      " 6 2 6 2 2 2 2 6 2 2 2 5 2 2 2 2 6 2 2 6 3 2 2 2 3 2 6 2 2 2 2 2 2 2 2 6 6\n",
      " 2 2 2 2 6 2 6 2 2 2 2 2 6 3 6 2 2 6 2 2 2 2 2 5 6 2 3 2 6 2 2 3 5 2 3 2 2\n",
      " 2 2 2 2 2 2 2 5 2 2 2 2 5 2 2 6 6 2 3 2 2 2 2 6 2 2 2 3 2 2 2 3 2 2 2 2 2\n",
      " 2 6 2 5 2 2 6 6 6 3 2 2 2 2 6 5 2 2 2 2 2 2 2 2 2 3 5 6 5 6 2 2 2 2 2 2 2\n",
      " 2 5 2 2 2 2 2 2 3 2 3 2 6 2 2 2 2 2 2 5 2 2 5 6 5 6 6 2 2 2 2 2 2 3 5 2 2\n",
      " 5 2 2 2 2 2 2 6 6 2 6 5 2 2 6 6 2 2 3 2 5 2 2 2 2 2 2 2 2 2 2 2 2 2 6 2 2\n",
      " 6 2 2 2 3 2 2 2 2 2 2 2 6 6 6 6 5 5 2 2 2 3 5 6 2 3 2 2 2 6 6 6 2 2 2 2 2\n",
      " 2 6 2 2 2 2 2 2 2 2 2 2 2 6 2 2 2 5 6 2 2 2 2 2 5 2 2 6 3 6 6 2 2 2 2 2 2\n",
      " 2 5 2 2 2 2 2 2 5 2 2 2 2 2 2 3 2 6 6]\n",
      "[  0   0 298  25   0  34  69]\n",
      "[0 1 2 3 4 5 6]\n",
      "[3 2 2 2 2 5 3 6 3 2 2 3 2 6 2 5 2 6 5 6 2 6 6 6 6 2 2 6 2 2 5 2 2 6 6 6 2\n",
      " 2 6 2 3 5 2 2 6 2 6 6 6 5 2 2 2 5 2 2 2 2 6 6 5 6 6 2 6 2 2 6 2 2 6 2 6 2\n",
      " 5 2 2 2 6 3 6 2 2 6 2 2 6 2 6 2 2 6 2 2 2 2 2 6 6 3 6 6 2 2 6 2 2 2 5 6 2\n",
      " 6 2 6 2 5 5 2 6 2 2 2 6 2 2 5 2 6 3 2 6 6 2 2 3 6 2 6 2 2 2 2 2 2 2 2 6 6\n",
      " 5 2 2 2 6 3 6 2 2 2 3 2 6 6 6 3 3 6 5 5 2 2 3 6 6 2 6 2 6 5 2 6 6 2 6 2 2\n",
      " 2 2 3 2 2 3 2 6 2 2 2 2 6 3 2 6 6 5 6 2 6 2 5 6 6 2 5 6 2 2 2 6 2 2 2 2 5\n",
      " 6 6 2 6 5 3 6 6 6 6 6 2 2 2 6 6 5 2 3 2 2 6 2 2 2 6 6 6 6 6 2 3 2 3 2 2 5\n",
      " 3 6 2 2 2 2 2 2 6 2 6 3 6 5 3 2 6 2 2 6 2 5 6 6 6 6 6 2 3 2 2 2 5 6 6 2 2\n",
      " 6 2 6 2 2 2 2 6 6 3 6 6 5 2 6 6 2 6 6 2 6 2 5 3 2 2 2 6 3 2 2 2 6 5 6 2 5\n",
      " 6 2 6 2 6 2 2 2 2 2 3 2 6 6 6 6 6 6 2 2 2 6 6 6 3 6 2 2 5 6 6 6 5 6 2 2 2\n",
      " 2 6 2 2 2 2 2 2 2 2 2 2 2 6 2 2 2 6 6 2 2 2 2 2 6 2 2 6 6 6 6 3 5 2 6 5 6\n",
      " 2 6 2 2 2 2 2 5 6 2 2 2 2 2 3 6 6 6 6]\n",
      "[  0   0 210  32   0  36 148]\n",
      "[0 1 2 3 4 5 6]\n",
      "[ 7  4  4  4  4 10  7 10  7  4  7  7  4 10  4 10  3  9 10 10  4 10 10 10\n",
      " 10  4  7 10  4  4 10  4  3 10 10 10  5  5 10  4 10 10  3  3 10  4  9 10\n",
      " 10  9  4  4  4 10  4  4  7  4 10 10 10 10 10  7 10  4  4 10  4  4 10  3\n",
      " 10  4  9  4  7  5  9  7 10  4  4 10  4  7 10  4 10  4  4 10  4  4  5  3\n",
      "  5 10 10  7 10 10  4  4 10  4  3  4 10 10  5 10  4 10  5  9 10  5 10  5\n",
      "  5  5 10  4  4 10  4 10  7  4 10 10  7  3  7 10  5 10  4  4  5  5  4  4\n",
      "  7  5 10 10 10  5  4  4 10  7 10  4  7  4  9  4  9 10 10  7  7 10  9 10\n",
      "  4  4  9 10 10  5 10  5 10  9  4  9  9  5 10  4  4  5  4 10  4  4  7  4\n",
      " 10  5  7  4  4 10  5  7 10  9  9 10  3 10  5 10 10 10  4 10 10 10  4  4\n",
      " 10  5  4  3  4 10  9 10  3 10 10  7 10 10  9 10 10  5  4  5 10 10 10  5\n",
      "  7  3  4 10  3  4  7 10  9 10 10 10  4  7  4  7  4  4  9  7 10  5  3  4\n",
      "  5  4  4 10  4 10  7 10 10  7  4  9  4  3 10  4 10 10 10 10 10 10  4  7\n",
      "  4  5  4 10 10 10  4  4 10  4 10  4  4  7  4 10 10  7 10 10 10  5 10 10\n",
      "  5  9 10  3 10  4 10  7  4  4  4 10  7  4  4  5 10  9 10  4  9 10  4 10\n",
      "  5 10  3  5  4  4  4  7  5 10 10 10 10 10 10  4  4  4 10 10 10  7 10  4\n",
      "  3 10 10 10 10  9 10  4  7  7  4 10  7  3  3  4  7  7  5  4  7  4  4 10\n",
      "  3  5  4 10 10  4  4  3  4  5 10  7  4 10 10 10 10  7 10  4 10 10 10  5\n",
      " 10  4  5  3  5  3 10 10  5  5  4  3  4  7  9 10 10 10]\n",
      "[  0   0   0  25 121  44   0  47   0  25 164]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10]\n",
      "[ 7  2  2  2  2 10  7 10  7  2  6  6  2 10  2  9  2 10  9 10  2 10 10 10\n",
      " 10  2  7 10  2  2  9  2  2 10 10 10  2  3 10  2  7  9  2  2 10  2 10 10\n",
      " 10 10  2  2  2  9  2  2  6  2 10 10  6 10 10  6 10  2  2 10  2  2 10  2\n",
      " 10  2  7  2  7  2 10  7 10  2  2 10  2  3 10  2 10  2  2 10  2  2  3  2\n",
      "  3 10 10  6 10 10  2  2 10  2  2  2  9 10  3 10  2 10  3 10 10  2 10  3\n",
      "  3  3 10  2  2  9  2 10  7  2 10 10  7  2  6 10  3 10  2  2  3  2  2  2\n",
      "  7  3 10 10 10  3  2  2 10  6 10  2  7  2  6  2 10 10 10  7  6 10  9  9\n",
      "  2  2  7 10 10  3 10  3 10  9  2 10 10  3 10  2  2  3  2  7  2  2  6  2\n",
      " 10  3  3  2  2 10  3  6 10 10  9 10  2 10  3  9 10 10  2  9 10  7  2  2\n",
      " 10  2  2  2  2  9 10 10  2 10 10  7 10 10 10 10 10  2  2  2 10 10  9  3\n",
      "  7  2  2 10  2  2  6 10 10 10 10 10  2  7  2  6  2  2 10  7 10  3  2  2\n",
      "  3  2  2 10  2 10  6 10  9  7  2 10  2  2 10  2  9 10 10 10 10 10  2  6\n",
      "  2  3  2  9 10 10  2  2 10  2 10  2  2  6  2 10 10  6 10 10  9  3 10 10\n",
      "  3 10 10  2 10  2 10  6  2  2  2 10  7  2  2  2 10  9 10  2 10 10  2 10\n",
      "  3 10  2  2  2  2  2  6  3 10 10 10 10 10 10  2  2  2 10 10 10  6 10  2\n",
      "  2  9 10 10 10  9 10  2  6  6  2 10  7  2  2  2  3  7  2  2  6  2  2 10\n",
      "  2  3  2 10 10  2  2  2  2  2 10  6  2 10 10 10 10  6  9  2 10  9 10  3\n",
      " 10  2  3  2  3  2  9 10  3  3  2  2  2  7 10 10 10 10]\n",
      "[  0   0 157  36   0   0  26  25   0  25 157]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10]\n",
      "Mean APL: 3.41\n",
      "Training surrogate model......\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Surrogate iters: [200]/[1000] loss: 6.70\n",
      "Surrogate iters: [400]/[1000] loss: 6.11\n",
      "Surrogate iters: [600]/[1000] loss: 5.78\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-a929225e0ac6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     45\u001b[0m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrn_y\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrn_x\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m             \u001b[0moutput\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msurrogate_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrn_x\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     48\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion_surrogate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrn_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m         \u001b[1;31m# l2 norm\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 550\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    551\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-4ca753327860>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mout1\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mout2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfc2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 550\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    551\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\linear.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 87\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mlinear\u001b[1;34m(input, weight, bias)\u001b[0m\n\u001b[0;32m   1610\u001b[0m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1611\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1612\u001b[1;33m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1613\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mbias\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1614\u001b[0m             \u001b[0moutput\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# train DNN with tree regularization\n",
    "model = NeuralNet(input_size, hidden_size, num_classes)\n",
    "model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# surrogate model\n",
    "surrogate_model = SurrogateModel()\n",
    "surrogate_model.to(device)\n",
    "criterion_surrogate = nn.MSELoss()\n",
    "#optimizer_surrogate = optim.SGD(surrogate_model.parameters(), lr=learning_rate, momentum=momentum)\n",
    "optimizer_surrogate = optim.Adam(surrogate_model.parameters(), lr=learning_rate)\n",
    "for i in range(num_retrains):\n",
    "    if i == 0 or i % 5 == 0:\n",
    "        saved_model_state_dict = [] # save the model state dict in each iters_retrain\n",
    "    # train DNN model\n",
    "    print('Training DNN model......')\n",
    "    for j in range(iters_retrain):\n",
    "        trn_x, trn_y = get_jth_minibatach(j, batch_size, X_train, y_train)\n",
    "        trn_x = trn_x.to(device)\n",
    "        trn_y = trn_y.to(device)\n",
    "        output = model(trn_x)\n",
    "        path_length = surrogate_model(model.named_parameters())\n",
    "        if i == 0:\n",
    "            loss = criterion(output, trn_y)\n",
    "        else:\n",
    "            loss = criterion(output, trn_y) + lambda_punish * path_length\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        saved_model_state_dict.append(copy.deepcopy(model.state_dict()))\n",
    "        if (i*iters_retrain + j + 1) % 10 == 0:\n",
    "            print('DNN iters: [{0}]/[{1}] loss: {2:.2f} Estimated APL: {3:.2f}'.format((i*iters_retrain + j + 1), num_iters, \n",
    "                                                                             loss.item(), path_length.item()))\n",
    "    # train Decision Tree to get {weights, APL} dataset\n",
    "    print('Get {weights, APL} dataset......')\n",
    "    y_APL_train = get_y_APL_train(saved_model_state_dict, X_train)\n",
    "    print('Mean APL: {0:.2f}'.format(y_APL_train.mean().item()))\n",
    "    print('Training surrogate model......')\n",
    "    # train surrogate model\n",
    "    for j in range(1000):\n",
    "        trn_x, trn_y = get_jth_minibatach(j, batch_size, saved_model_state_dict, y_APL_train)\n",
    "        trn_y = trn_y.to(device)\n",
    "        output = torch.zeros(trn_y.size(0), device=device)\n",
    "        for k in range(len(trn_x)):\n",
    "            output[k] = surrogate_model(trn_x[k].items())\n",
    "        loss = criterion_surrogate(output, trn_y)\n",
    "        # l2 norm\n",
    "        l2_norm = 0\n",
    "        for key, value in surrogate_model.named_parameters():\n",
    "            if key.endswith('weight'):\n",
    "                l2_norm += value.norm()\n",
    "        loss += epsilon_punish * l2_norm\n",
    "        optimizer_surrogate.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer_surrogate.step()\n",
    "        if (j+1) % 200 == 0:\n",
    "            print('Surrogate iters: [{0}]/[1000] loss: {1:.2f}'.format(j+1, loss.item()))\n",
    "    if i % 3 == 0:\n",
    "        with torch.no_grad():\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            X_test = X_test.to(device)\n",
    "            y_test = y_test.to(device)\n",
    "            outputs = model(X_test)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += y_test.size(0)\n",
    "            correct += (predicted == y_test).sum().item()\n",
    "            y_score = F.softmax(outputs, dim=1)\n",
    "            y_score = y_score[:, 1]\n",
    "\n",
    "            print('Accuracy of the network on the Breast Cancer dataset: {0:.2f} %'.format(100 * correct / total))\n",
    "            print('AUC of the network on the Breast Cancer dataset: {0:.2f}'.format(roc_auc_score(y_test.cpu().numpy(), y_score.cpu().numpy())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the Breast Cancer dataset: 88.1118881118881 %\n",
      "AUC of the network on the Breast Cancer dataset: 0.97\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    X_test = X_test.to(device)\n",
    "    y_test = y_test.to(device)\n",
    "    outputs = model(X_test)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    total += y_test.size(0)\n",
    "    correct += (predicted == y_test).sum().item()\n",
    "    y_score = F.softmax(outputs, dim=1)\n",
    "    y_score = y_score[:, 1]\n",
    "\n",
    "    print('Accuracy of the network on the Breast Cancer dataset: {0} %'.format(100 * correct / total))\n",
    "    print('AUC of the network on the Breast Cancer dataset: {0:.2f}'.format(roc_auc_score(y_test.cpu().numpy(), y_score.cpu().numpy())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), './models/dnn_model_' + str(lambda_punish) + '.pth')\n",
    "torch.save(surrogate_model.state_dict(), './models/surrogate_model_' + str(lambda_punish) + '.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8881118881118881\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# visualize\n",
    "model = NeuralNet(input_size, hidden_size, num_classes)\n",
    "model.to(device)\n",
    "model.load_state_dict(torch.load('./models/dnn_model_' + str(lambda_punish) + '.pth', map_location=torch.device('cpu')))\n",
    "X_train = X_train.to(device)\n",
    "outputs = model(X_train)\n",
    "_, y_pred = torch.max(outputs.data, 1)\n",
    "tree = DecisionTreeClassifier(min_samples_leaf=25)\n",
    "X_train = X_train.to(torch.device('cpu'))\n",
    "y_pred = y_pred.to(torch.device('cpu'))\n",
    "tree.fit(X_train.numpy(), y_pred.numpy())\n",
    "print(accuracy_score(y_test.cpu().numpy(), tree.predict(X_test.cpu().numpy())))\n",
    "dot_data = export_graphviz(tree, out_file=None,\n",
    "                           feature_names=data.feature_names,\n",
    "                           class_names=data.target_names,\n",
    "                           filled=True, rounded=True,\n",
    "                           special_characters=True)\n",
    "graph = pydotplus.graph_from_dot_data(dot_data)\n",
    "graph.write_pdf('./visualize/tree_on_dnn_regularization_visualize_' + str(lambda_punish) + '.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the decision tree on original dataset: 95.10 %\n",
      "AUC of the decision tree on original dataset: 0.98\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# visualize tree trained on original dataset\n",
    "tree = DecisionTreeClassifier(min_samples_leaf=25)\n",
    "X_train = X_train.to(torch.device('cpu'))\n",
    "y_train = y_train.to(torch.device('cpu'))\n",
    "tree.fit(X_train.numpy(), y_train.numpy())\n",
    "y_pred = tree.predict(X_test)\n",
    "y_score = tree.predict_proba(X_test)[:, 1]\n",
    "print('Accuracy of the decision tree on original dataset: {0:.2f} %'.format(accuracy_score(y_test, y_pred)*100))\n",
    "print('AUC of the decision tree on original dataset: {0:.2f}'.format(roc_auc_score(y_test, y_score)))\n",
    "dot_data = export_graphviz(tree, out_file=None,\n",
    "                           feature_names=data.feature_names,\n",
    "                           class_names=data.target_names,\n",
    "                           filled=True, rounded=True,\n",
    "                           special_characters=True)\n",
    "graph = pydotplus.graph_from_dot_data(dot_data)\n",
    "graph.write_pdf('./visualize/decision_tree_on_original_dataset_visualize.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
